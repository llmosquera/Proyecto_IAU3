{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Montar Disco"
      ],
      "metadata": {
        "id": "qQu9DMpWucK0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yxgyajo2mOvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc94a9a-c0ac-4924-8f74-315bf096478a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importar Librerias"
      ],
      "metadata": {
        "id": "m-mmbw1duXcs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B2JwrUssluFH"
      },
      "outputs": [],
      "source": [
        "# importar librerias \n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import keras\n",
        "import numpy as np\n",
        "import  cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Datos"
      ],
      "metadata": {
        "id": "K4FhFqt8mZhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pqgKAHYFm0Hw"
      },
      "outputs": [],
      "source": [
        "# ruta de la carpeta con la imagenes procesadas\n",
        "folder = '/content/MyDrive/MyDrive/ProyectoIA_U3/New_data'\n",
        "# tamaÃ±o de batch o lote \n",
        "batch_size = 60\n",
        "#altura de  imagen \n",
        "img_height = 192\n",
        "# ancho de imagen \n",
        "img_width = 192"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4wG4jvym-WC",
        "outputId": "c9166638-cb70-4665-f7e6-7728d2554025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4077 files belonging to 26 classes.\n",
            "Using 3670 files for training.\n"
          ]
        }
      ],
      "source": [
        "# data set de entrenamiento \n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  folder, #ruta de las carpetas \n",
        "  validation_split=0.1, # porcetanje de datos para  validacion\n",
        "  subset=\"training\", # especificamos que es el dataset de entrenamiento \n",
        "  color_mode ='rgb', # modo de imagen rgb ==> 3 canales\n",
        "  seed=222, # semilla para  el den aleatorio de  imagenes \n",
        "  label_mode = 'int', # modo la etiqueta \n",
        "  image_size=(img_height, img_width), # alto  ancho de imagen \n",
        "  batch_size=batch_size # batch \n",
        "  ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvS8wSTDnBYL",
        "outputId": "17339192-9088-4a75-915a-cf926cc9686a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4077 files belonging to 26 classes.\n",
            "Using 407 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  folder, #ruta de las carpetas \n",
        "  validation_split=0.1,# porcetanje de datos para  validacion\n",
        "  subset=\"validation\",# especificamos que es el dataset de validacion\n",
        "  color_mode ='rgb',# modo de imagen rgb ==> 3 canales\n",
        "  seed=222,# semilla para  el den aleatorio de  imagenes \n",
        "  label_mode = 'int',# modo la etiqueta \n",
        "  image_size=(img_height, img_width),# alto  ancho de imagen \n",
        "  batch_size=batch_size)# batch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIDhqprtncUs",
        "outputId": "37c1c5b6-7b7d-4536-ea05-6522aa10f07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "['Ariel Chabla', 'ArroboMercy', 'BarraganSteven', 'CevallosJoan', 'EnriquezSelena', 'GenesisHeredia', 'GoyesAnthony', 'HectorCedeno', 'Jhon Zambrano', 'Jordan Espinosa', 'Jorge Borrero', 'JoseRuiz', 'LucioCarlos', 'MasacheFernando', 'MelanyLopez', 'MosqueraLucy', 'Nataly Acosta', 'OlallaLuis', 'ParragaMariaJose', 'PauteKevin', 'Raymond Davila', 'RivasSelena', 'SalazarJohana', 'Solano Wilmer', 'SolorzanoBryan', 'VinicioBorja']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(len(class_names))\n",
        "class_names = val_ds.class_names\n",
        "print((class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85nfplIVnexU",
        "outputId": "5759ffd9-dee2-4b80-f9ff-b994cead2ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 192, 192, 3)\n",
            "(60,)\n"
          ]
        }
      ],
      "source": [
        "# muestra o imprime la forma de los tensores de la imagen y etiqueta\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# muestra o imprime la forma de los tensores de la imagen y etiqueta\n",
        "images = []\n",
        "labels = []\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  images.append(image_batch)\n",
        "  images.append(labels_batch)\n",
        "  break"
      ],
      "metadata": {
        "id": "P4-0kGEzG238"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mostrar los valore de los  pixels en el tensor de images\n",
        "print(images)"
      ],
      "metadata": {
        "id": "iSpDn6YtGley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalizacion"
      ],
      "metadata": {
        "id": "mYAgFHrSmgW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcGDN66TnhVD",
        "outputId": "3e81a2a3-4178-4f44-ad0e-1e57fee95a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#capa de normalizacion para pasar los valores de los pixles de 0 a 255 y nomralizarolos entre 0 y 1\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "#aplico la normalizacion al dat set de entrenamiento \n",
        "Ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "#aplico la normalizacion al dat set de validacion\n",
        "Nval_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "image_batch, labels_batch = next(iter(Nval_ds))\n",
        "first_image = image_batch[0]\n",
        "print(np.min(first_image), np.max(first_image))\n",
        "\n",
        "# optimizacion para guardar  valores en cache \n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "Ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "Nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AlexNet"
      ],
      "metadata": {
        "id": "E8c29QZBl8WE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "6lHcdFmfl_XA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
      ],
      "metadata": {
        "id": "VM0A4TeppOqM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ejemplo creacion rapida \n",
        "modelo1 = tf.keras.models.Sequential()\n",
        "modelo1.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(192,192,3)))\n",
        "modelo1.add(tf.keras.layers.Dense(100,activation='relu'))\n",
        "modelo1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR7vLmpQNQDs",
        "outputId": "76235cf3-5702-4867-96e4-cc0efe5052f2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 46, 46, 96)        34944     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 46, 46, 100)       9700      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,644\n",
            "Trainable params: 44,644\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70eTn-3yNg_M",
        "outputId": "54b04a3b-1fb7-456d-c914-6048fb4d9fef"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 46, 46, 96)        34944     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,944\n",
            "Trainable params: 34,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Alexnet"
      ],
      "metadata": {
        "id": "dwAEuXaLTDMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Alexnet = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(192,192,3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2048, activation='relu'),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(26, activation='softmax')\n",
        "])\n",
        "\n",
        "Alexnet.summary()"
      ],
      "metadata": {
        "id": "-MD_1tVWTgPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c8bd2b-8078-48c0-89b5-e83f0c7c94ef"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 46, 46, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 46, 46, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 22, 22, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 22, 22, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 22, 22, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 10, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 10, 10, 384)       885120    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 10, 10, 384)       1327488   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 10, 10, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 10, 10, 256)       884992    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 10, 10, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2048)              8390656   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 26)                26650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47,830,810\n",
            "Trainable params: 47,828,058\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizador \n"
      ],
      "metadata": {
        "id": "xrq1tX9qLjYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#learning rate\n",
        "lr_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0003,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "#ADAM\n",
        "optAdam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr_rate)\n",
        "#SGD\n",
        "optSgd=tf.keras.optimizers.SGD(\n",
        "    learning_rate=lr_rate,\n",
        "    momentum=0.9,\n",
        "    nesterov=False,\n",
        "    name='SGD')"
      ],
      "metadata": {
        "id": "p7tgYP1btfWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compiler"
      ],
      "metadata": {
        "id": "LX8iy0FwtVK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Alexnet.compile(\n",
        "  optimizer='Adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "j9hyKlW-tbG8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Callbacks"
      ],
      "metadata": {
        "id": "-0SsC4Iktwwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alexnetlog = TensorBoard(log_dir='/content/model')\n",
        "\n",
        "earlingstop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=False\n",
        ")\n",
        "\n",
        "Saves = '/content/model/Alexnet34.h5'\n",
        "#cheppoints\n",
        "Checkp = tf.keras.callbacks.ModelCheckpoint(\n",
        "    Saves,\n",
        "    monitor='accuracy',\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto',\n",
        "    save_freq='epoch',\n",
        "    options=None,\n",
        "    initial_value_threshold=None\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "PC5A8bnQUXQn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenamiento"
      ],
      "metadata": {
        "id": "hPy-ZNiAtncZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = Alexnet.fit(\n",
        "  Ntrain_ds,\n",
        "  validation_data=Nval_ds,\n",
        "  epochs=100,\n",
        "  callbacks = [alexnetlog,earlingstop,Checkp]\n",
        ")"
      ],
      "metadata": {
        "id": "rJs11tH3Un61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b081de59-1b85-43aa-91e0-ddb2066da631"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 687s 11s/step - loss: 4.4151 - accuracy: 0.0766 - val_loss: 21.7057 - val_accuracy: 0.0590\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 6s 97ms/step - loss: 2.8072 - accuracy: 0.1706 - val_loss: 7.0134 - val_accuracy: 0.0663\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 6s 95ms/step - loss: 2.4269 - accuracy: 0.2515 - val_loss: 3.7673 - val_accuracy: 0.1007\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 6s 96ms/step - loss: 2.0731 - accuracy: 0.3490 - val_loss: 3.6755 - val_accuracy: 0.1302\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 6s 95ms/step - loss: 1.7758 - accuracy: 0.4240 - val_loss: 3.6981 - val_accuracy: 0.1572\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 6s 95ms/step - loss: 1.5865 - accuracy: 0.5011 - val_loss: 3.8170 - val_accuracy: 0.2408\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 6s 95ms/step - loss: 1.4329 - accuracy: 0.5422 - val_loss: 2.8000 - val_accuracy: 0.3489\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 6s 95ms/step - loss: 1.2042 - accuracy: 0.6172 - val_loss: 6.1493 - val_accuracy: 0.1916\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 6s 101ms/step - loss: 1.1250 - accuracy: 0.6523 - val_loss: 5.3311 - val_accuracy: 0.1892\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 6s 93ms/step - loss: 0.9680 - accuracy: 0.6970 - val_loss: 11.6341 - val_accuracy: 0.1057\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 4s 64ms/step - loss: 1.0534 - accuracy: 0.6861 - val_loss: 4.7005 - val_accuracy: 0.3022\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 6s 96ms/step - loss: 0.8499 - accuracy: 0.7433 - val_loss: 2.4996 - val_accuracy: 0.4816\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 6s 96ms/step - loss: 0.7945 - accuracy: 0.7698 - val_loss: 6.7497 - val_accuracy: 0.2211\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 4s 64ms/step - loss: 0.9630 - accuracy: 0.7267 - val_loss: 5.4318 - val_accuracy: 0.3243\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 6s 95ms/step - loss: 0.6779 - accuracy: 0.8022 - val_loss: 6.6882 - val_accuracy: 0.2088\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 4s 64ms/step - loss: 0.6806 - accuracy: 0.7984 - val_loss: 2.8318 - val_accuracy: 0.5921\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 6s 97ms/step - loss: 0.6309 - accuracy: 0.8248 - val_loss: 9.3093 - val_accuracy: 0.2703\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 6s 97ms/step - loss: 0.5980 - accuracy: 0.8351 - val_loss: 1.5678 - val_accuracy: 0.6904\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 6s 97ms/step - loss: 0.5585 - accuracy: 0.8477 - val_loss: 1.1047 - val_accuracy: 0.7764\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 6s 95ms/step - loss: 0.4986 - accuracy: 0.8599 - val_loss: 3.0262 - val_accuracy: 0.4545\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 6s 97ms/step - loss: 0.4230 - accuracy: 0.8858 - val_loss: 6.1460 - val_accuracy: 0.3882\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 6s 99ms/step - loss: 0.4031 - accuracy: 0.8932 - val_loss: 3.3433 - val_accuracy: 0.4914\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 6s 97ms/step - loss: 0.3450 - accuracy: 0.9098 - val_loss: 2.8820 - val_accuracy: 0.5405\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 6s 97ms/step - loss: 0.3141 - accuracy: 0.9215 - val_loss: 3.8203 - val_accuracy: 0.5111\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.3490 - accuracy: 0.9131 - val_loss: 2.1115 - val_accuracy: 0.6536\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 4s 64ms/step - loss: 0.4090 - accuracy: 0.9057 - val_loss: 1.3831 - val_accuracy: 0.8084\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 6s 98ms/step - loss: 0.3166 - accuracy: 0.9251 - val_loss: 4.7100 - val_accuracy: 0.4472\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 6s 99ms/step - loss: 0.3001 - accuracy: 0.9300 - val_loss: 0.7283 - val_accuracy: 0.8452\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.3132 - accuracy: 0.9289 - val_loss: 3.0791 - val_accuracy: 0.6241\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 6s 99ms/step - loss: 0.2642 - accuracy: 0.9411 - val_loss: 0.9478 - val_accuracy: 0.8231\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.4282 - accuracy: 0.9063 - val_loss: 1.8971 - val_accuracy: 0.6904\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.3709 - accuracy: 0.9180 - val_loss: 12.9444 - val_accuracy: 0.1302\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.3093 - accuracy: 0.9270 - val_loss: 6.0892 - val_accuracy: 0.4545\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 6s 98ms/step - loss: 0.1568 - accuracy: 0.9646 - val_loss: 7.1695 - val_accuracy: 0.3808\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2569 - accuracy: 0.9482 - val_loss: 3.1855 - val_accuracy: 0.6437\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.3128 - accuracy: 0.9338 - val_loss: 1.3615 - val_accuracy: 0.8010\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.4325 - accuracy: 0.9041 - val_loss: 6.8172 - val_accuracy: 0.4447\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.3023 - accuracy: 0.9379 - val_loss: 2.6684 - val_accuracy: 0.6658\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.2465 - accuracy: 0.9362 - val_loss: 2.3899 - val_accuracy: 0.6929\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.2172 - accuracy: 0.9559 - val_loss: 2.5994 - val_accuracy: 0.7101\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.3192 - accuracy: 0.9390 - val_loss: 17.9105 - val_accuracy: 0.1425\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.3965 - accuracy: 0.9311 - val_loss: 2.3095 - val_accuracy: 0.6364\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-b6540448076a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malexnetlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearlingstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCheckp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid Search\n"
      ],
      "metadata": {
        "id": "9paBM44NS7sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from matplotlib.rcsetup import ValidateInterval\n",
        "from tensorflow.python.ops.variables import VariableAggregationV2\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "CEbhdfyYTHYq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "dataset = datagen.flow_from_directory(folder, class_mode='categorical', batch_size= 50)\n",
        "\n",
        "X_image, Y_labels = dataset.next()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b7JJkdeS9Ut",
        "outputId": "211aef37-e039-45ee-dfb0-b9f58d6f8ac8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4077 images belonging to 26 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_modelA():\n",
        "  Alexnet = tf.keras.models.Sequential([\n",
        "\n",
        "          tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(256,256,3)),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "          tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "          tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(4096, activation='relu'),\n",
        "          tf.keras.layers.Dropout(0.3),\n",
        "          tf.keras.layers.Dense(4096, activation='relu'),\n",
        "          tf.keras.layers.Dropout(0.5),\n",
        "          tf.keras.layers.Dense(2048, activation='relu'),\n",
        "          tf.keras.layers.Dense(1024, activation='relu'),\n",
        "          tf.keras.layers.Dropout(0.5),\n",
        "          tf.keras.layers.Dense(26, activation='softmax')\n",
        "      ])\n",
        "        # compile model\n",
        "        #opt = SGD(lr=0.001, momentum=0.9)\n",
        "  opt = tf.keras.optimizers.SGD( learning_rate=0.01,    momentum=0.9)\n",
        "  Alexnet .compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return Alexnet\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n"
      ],
      "metadata": {
        "id": "lqSVimfaTanh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=create_modelA, verbose=0)\n",
        "\n",
        "batch_size = [32,80, 100]\n",
        "epochs = [ 10, 50, 100]\n",
        "\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,verbose=0, cv=3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFBH33TWTonS",
        "outputId": "1cd04a5e-d0c2-4047-8c35-4996993facae"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(X_image, Y_labels)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIrrx7rqV2vJ",
        "outputId": "19a3fdb5-67c3-4f61-9f3e-5e0a94305bfd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 298 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb18c65fe60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 299 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb18c7f3200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.139706 using {'batch_size': 80, 'epochs': 50}\n",
            "0.000000 (0.000000) with: {'batch_size': 32, 'epochs': 10}\n",
            "0.020833 (0.029463) with: {'batch_size': 32, 'epochs': 50}\n",
            "0.020833 (0.029463) with: {'batch_size': 32, 'epochs': 100}\n",
            "0.039216 (0.055459) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.139706 (0.026169) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.120098 (0.048154) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.139706 (0.026169) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.040441 (0.028636) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.078431 (0.073366) with: {'batch_size': 100, 'epochs': 100}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Alexnet2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}